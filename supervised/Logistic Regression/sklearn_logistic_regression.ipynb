{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f8e9823-dde6-42a5-9afa-a04a9ec7e9f8",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "+ Logistic regression is used to perform **binary classification**.\n",
    "+ Logistic regression is an extension of linear regression where we use a logit link function to fit a sigmoid curve to the data, rather than a line.\n",
    "+ We can use the coefficients from a logistic regression model to estimate the log odds that a datapoint belongs to the positive class. We can then transform the log odds into a probability.\n",
    "+ The coefficients of a logistic regression model can be used to estimate relative feature importance.\n",
    "+ A classification threshold is used to determine the probabilistic cutoff for where a data sample is classified as belonging to a positive or negative class. The default cutoff in sklearn is 0.5.\n",
    "+ We can evaluate a logistic regression model using a confusion matrix or summary statistics such as accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4400d62-443c-4b33-895a-9bdca491c193",
   "metadata": {},
   "source": [
    "## Fitting a model in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b81fcbc-f1de-4ef3-b345-3ffb51cf9678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hours_studied  practice_test  passed_exam\n",
      "0              0             55            0\n",
      "1              1             75            0\n",
      "2              2             32            0\n",
      "3              3             80            0\n",
      "4              4             75            0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "codecademyU = pd.read_csv('data.csv')\n",
    "print(codecademyU.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "152f0ffa-78ca-4b2f-b779-c6d1a0d5a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5100409  0.12002228]]\n",
      "[-0.13173123]\n"
     ]
    }
   ],
   "source": [
    "# Import pandas and the data\n",
    "import pandas as pd\n",
    "codecademyU = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "# Separate out X and y\n",
    "X = codecademyU[['hours_studied', 'practice_test']]\n",
    "y = codecademyU.passed_exam\n",
    "\n",
    "\n",
    "# Transform X\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 27)\n",
    "\n",
    "\n",
    "# Create and fit the logistic regression model here:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "cc_lr = LogisticRegression()\n",
    "cc_lr.fit(X_train, y_train)\n",
    "# Print the intercept and coefficients here:\n",
    "print(cc_lr.coef_)\n",
    "print(cc_lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc5201-d230-4abb-b88a-34562936609e",
   "metadata": {},
   "source": [
    "## Predictions in sklearn\n",
    "\n",
    "Using a trained model, we can predict whether new datapoints belong to the positive class (the group labeled as 1) using the .predict() method. The input is a matrix of features and the output is a vector of predicted labels, 1 or 0.\n",
    "\n",
    "print(model.predict(features))\n",
    "\n",
    "Sample output: [0 1 1 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e3a4a-02ea-48f5-a356-ca81931c048d",
   "metadata": {},
   "source": [
    "If we are more interested in the **predicted probability** of group membership, we can use the .predict_proba() method. The input to predict_proba() is also a matrix of features and the output is an array of probabilities, ranging from 0 to 1:\n",
    "\n",
    "print(model.predict_proba(features)[:,1])\n",
    "\n",
    "Sample output: [0.32 0.75  0.55 0.20 0.44]\n",
    "\n",
    "\n",
    "By default, .predict_proba() returns the probability of class membership for both possible groups. In the example code above, we’ve only printed out the probability of belonging to the positive class. Notice that datapoints with predicted probabilities greater than 0.5 (the second and third datapoints in this example) were classified as 1s by the .predict() method. This is a process known as thresholding. As we can see here, sklearn sets the default classification threshold probability as 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b468a345-6980-438c-b2e0-a38c8d46a53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1]\n",
      "\n",
      "[[-0.43355498  0.29722219]\n",
      " [ 0.95382097  0.29722219]\n",
      " [-1.64750894 -1.79313169]\n",
      " [ 0.26013299  0.42786931]\n",
      " [ 1.30066495  0.62383999]]\n",
      "\n",
      "[[0.67934073 0.32065927]\n",
      " [0.2068119  0.7931881 ]\n",
      " [0.94452517 0.05547483]\n",
      " [0.42252072 0.57747928]\n",
      " [0.12929566 0.87070434]]\n",
      "\n",
      "7     0\n",
      "15    1\n",
      "0     0\n",
      "11    0\n",
      "17    1\n",
      "Name: passed_exam, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print out the predicted outcomes for the test data\n",
    "print(cc_lr.predict(X_test))\n",
    "print()\n",
    "print(X_test)\n",
    "print()\n",
    "# Print out the predicted probabilities for the test data\n",
    "print(cc_lr.predict_proba(X_test))\n",
    "print()\n",
    "# Print out the true outcomes for the test data\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fac5ed-a8da-4ae4-9729-a97cd1c954ca",
   "metadata": {},
   "source": [
    "### Understanding prediction results\n",
    "\n",
    "With predict_proba(), the return values relate to the probability of the prediction being 0 ('fail) or 1 ('pass'). In the case of sample 1 here, [0.67934073 0.32065927], there is a 68% probability of a fail, 32% probability of a pass (adding up to 100%).\n",
    "\n",
    "You should see that the fourth datapoint was incorrectly classified as having passed the exam; however, the predicted probability of passing for this datapoint was only 57.7%, which is much lower than the other students who were correctly predicted to pass the exam (79.3% and 87.1%, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de875200-0148-478e-a2d3-9dd29c504383",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "When we fit a machine learning model, we need some way to evaluate it. Often, we do this by splitting our data into training and test datasets. We use the training data to fit the model; then we use the test set to see how well the model performs with new data.\n",
    "\n",
    "As a first step, data scientists often look at a confusion matrix, which shows the number of true positives, false positives, true negatives, and false negatives.\n",
    "\n",
    "For example, suppose that the true and predicted classes for a logistic regression model are:\n",
    "\n",
    "y_true = [0, 0, 1, 1, 1, 0, 0, 1, 0, 1]\n",
    "\n",
    "y_pred = [0, 1, 1, 0, 1, 0, 1, 1, 0, 1]\n",
    "\n",
    "\n",
    "We can create a confusion matrix as follows:\n",
    "\n",
    "+ from sklearn.metrics import confusion_matrix\n",
    "+ print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "\n",
    "Output:\n",
    "    \n",
    "    array([[3, 2]\n",
    "    \n",
    "           [1, 4]])\n",
    "\n",
    "\n",
    "This output tells us that there are 3 true negatives, 1 false negative, 4 true positives, and 2 false positives. Ideally, we want the numbers on the main diagonal (in this case, 3 and 4, which are the true negatives and true positives, respectively) to be as large as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4070b1bc-d08f-4cc9-b207-50b653591e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted classes:  [0 1 0 1 1]\n",
      "true classes:  7     0\n",
      "15    1\n",
      "0     0\n",
      "11    0\n",
      "17    1\n",
      "Name: passed_exam, dtype: int64\n",
      "[[2 1]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "# Save and print the predicted outcomes\n",
    "y_pred = cc_lr.predict(X_test)\n",
    "print('predicted classes: ', y_pred)\n",
    "\n",
    "# Print out the true outcomes for the test data\n",
    "print('true classes: ', y_test)\n",
    "\n",
    "# Print out the confusion matrix here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e3256-d716-4752-a908-a590bc5cb1c6",
   "metadata": {},
   "source": [
    "## Accuracy, Recall, Precision, F1 Score\n",
    "\n",
    "Once we have a confusion matrix, there are a few different statistics we can use to summarize the four values in the matrix. These include accuracy, precision, recall, and F1 score. We won’t go into much detail about these metrics here, but a quick summary is shown below (T = true, F = false, P = positive, N = negative). \n",
    "\n",
    "For all of these metrics, a value closer to 1 is better and closer to 0 is worse.\n",
    "\n",
    "+ Accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "+ Precision = TP/(TP + FP)\n",
    "+ Recall = TP/(TP + FN)\n",
    "+ F1 score: weighted average of precision and recall\n",
    "\n",
    "In sklearn, we can calculate these metrics as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "314eedda-b058-4395-955b-506fd8bd70fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Outputs are taken from the example values above (y_true = [0, 0, 1, 1, 1, 0, 0, 1, 0, 1] and y_pred = [0, 1, 1, 0, 1, 0, 1, 1, 0, 1])\n",
    "\n",
    "# accuracy:\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# output: 0.7\n",
    "\n",
    "# precision:\n",
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(y_test, y_pred))\n",
    "# output: 0.67\n",
    "\n",
    "# recall:\n",
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, y_pred))\n",
    "# output: 0.8\n",
    "\n",
    "# F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, y_pred))\n",
    "# output: 0.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dcddb5-1299-43f5-a09e-497a7a6ebabb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
